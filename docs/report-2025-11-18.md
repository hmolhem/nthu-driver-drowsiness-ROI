# Daily Progress Report - November 18, 2025

## Project: NTHU Driver Drowsiness Detection with ROI

---

## Summary
Attempted to run baseline ResNet50 training locally on CPU after encountering GPU setup challenges in Colab. Created optimized training configurations for CPU but faced performance limitations. Identified GPU requirement for practical training.

---

## Work Completed

### 1. Colab GPU Training Attempt (Continued from Nov 17)
**Time:** ~2-3 hours  
**Status:** ❌ Unsuccessful

**Issues Encountered:**
- **GPU Runtime Not Enabled:** Initial runs defaulted to CPU despite L4 GPU availability
- **PyTorch Version Mismatch:** `requirements.txt` pinned torch==2.1.2, but Colab only offered 2.2.0+
- **Dataset Path Mismatch:** CSV filenames expected `drowsy/*.jpg` but symlink pointed to `train_data/drowsy/*.jpg`
- **Missing src/models Package:** Earlier .gitignore pattern excluded the models directory (fixed Nov 17)

**Actions Taken:**
- Updated `requirements.txt`: Removed TensorFlow/Keras dependencies, unpinned torch/torchvision
- Fixed .gitignore pattern and committed missing `src/models/` files
- Provided step-by-step Colab GPU setup instructions
- Created dataset symlink fix: `ln -s /content/drive/MyDrive/datasets/archive datasets/archive`

**Outcome:** User decided to try local Windows training instead

---

### 2. Local Windows Training Setup
**Time:** ~1-2 hours  
**Status:** ⚠️ Partial Success (setup complete, training too slow)

**Successes:**
- ✅ Installed PyTorch 2.5.1+cu121 (GPU-enabled build)
- ✅ Installed all dependencies (pandas, scikit-learn, matplotlib, seaborn, tqdm, opencv-python, Pillow, PyYAML)
- ✅ Created `configs/baseline_resnet50_fast.yaml` (160px, batch 16, 5 epochs)
- ✅ Created `configs/baseline_resnet50_ultrafast.yaml` (128px, batch 8, 2 epochs)
- ✅ Fixed data_root path: `datasets/archive` (local structure has images directly under archive/)

**Issues:**
- ❌ **No NVIDIA GPU detected:** `CUDA available: False` despite installing CUDA-enabled PyTorch
- ❌ **CPU training too slow:** 1.4 seconds/batch → 10-15+ hours for minimal 2-epoch run
- ❌ **Training interrupted twice:** User stopped due to excessive time

**Performance Metrics (CPU):**
- Epoch 1 progress: 13% complete in 9 minutes (ultrafast config)
- Estimated total time: ~10-12 hours for 2 epochs
- Dataset: 25,572 training images, 3,196 batches (batch size 8)

---

### 3. Configuration Files Created
**Status:** ✅ Completed and Committed

Created two new training configurations optimized for different scenarios:

#### `configs/baseline_resnet50_fast.yaml`
```yaml
image_size: 160
batch_size: 16
epochs: 5
num_workers: 0          # Windows-friendly
pin_memory: false
data_root: "datasets/archive"
experiment_name: "baseline_resnet50_fast"
```

**Target:** Local GPU or Colab GPU (if user had NVIDIA card)

#### `configs/baseline_resnet50_ultrafast.yaml`
```yaml
image_size: 128
batch_size: 8
epochs: 2
early_stopping: false
data_root: "datasets/archive"
experiment_name: "baseline_resnet50_ultrafast"
```

**Target:** CPU testing (still impractical for full dataset)

**Git Commit:** `c9b31aa` - "feat: add fast and ultrafast CPU training configs"

---

## Files Modified/Created

### New Files
- `configs/baseline_resnet50_fast.yaml` (new)
- `configs/baseline_resnet50_ultrafast.yaml` (new)

### Modified Files
- `requirements.txt` (removed TensorFlow/Keras, unpinned torch/torchvision, added Pillow/PyYAML)
- `.gitignore` (fixed `/models/` pattern to preserve `src/models/`)

### Repository Commits
1. `0e1ac7a` - chore: remove TensorFlow/Keras from requirements for Colab PyTorch training
2. `24238e5` - chore(colab): unpin torch/torchvision; add Pillow and PyYAML
3. `c9b31aa` - feat: add fast and ultrafast CPU training configs

---

## Time Breakdown

| Activity | Duration | Status |
|----------|----------|--------|
| Colab GPU troubleshooting | ~2 hours | Incomplete |
| Requirements.txt fixes | ~30 min | ✅ Complete |
| Local PyTorch installation | ~30 min | ✅ Complete |
| Config creation & testing | ~1 hour | ✅ Complete |
| CPU training attempts (2x) | ~20 min (stopped early) | ❌ Failed (too slow) |
| Git commits & documentation | ~30 min | ✅ Complete |
| **Total** | **~5 hours** | **Partially successful** |

---

## Challenges & Lessons Learned

### Challenge 1: GPU Availability
**Problem:** User's local machine has no NVIDIA GPU; Colab GPU setup proved confusing  
**Impact:** Cannot run practical training (CPU is 50-100x slower)  
**Lesson:** Deep learning with 25K+ images requires GPU; should have validated hardware earlier

### Challenge 2: Environment Compatibility
**Problem:** Colab Python 3.12 vs local Python 3.10; version pinning conflicts  
**Solution:** Unpinned torch/torchvision, removed unnecessary TensorFlow dependencies  
**Lesson:** Keep requirements.txt flexible for multi-environment support

### Challenge 3: Dataset Path Variations
**Problem:** Different directory structures (Colab: `train_data/`, local: direct)  
**Solution:** Created separate configs with appropriate `data_root` settings  
**Lesson:** Environment-specific configs needed for reproducibility

### Challenge 4: Windows Multiprocessing
**Problem:** DataLoader `num_workers > 0` causes issues on Windows  
**Solution:** Set `num_workers: 0` in all Windows configs  
**Lesson:** Platform-specific settings should be documented

---

## Next Steps

### Immediate Priorities
1. **✅ Complete Colab GPU Setup** (CRITICAL)
   - User needs to enable GPU runtime (Runtime → Change runtime type → GPU)
   - Install CUDA PyTorch: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121`
   - Fix dataset symlink: `mkdir -p datasets; ln -s /content/drive/MyDrive/datasets/archive datasets/archive`
   - Run training: `python src/training/train_baseline.py --config configs/baseline_resnet50.yaml --device cuda`
   - **Estimated time:** ~30-60 minutes on T4/L4 GPU

2. **Verify Checkpoints & Metrics**
   - Check `checkpoints/baseline_resnet50_best.pth` exists after epoch 1
   - Validate macro-F1, accuracy, confusion matrix
   - Download checkpoints from Colab to local `checkpoints/`

3. **Run Evaluation**
   - Load best checkpoint
   - Compute test set metrics
   - Generate classification report and confusion matrix

### Future Work
4. Train EfficientNet-B0 baseline for comparison
5. Begin ROI gating module implementation
6. Create comparison tables and plots
7. Test robustness transforms

---

## Recommendations

### For User
1. **Use Colab GPU** for all training (free, fast, practical)
2. Keep local environment for code editing, notebooks, evaluation only
3. Download trained checkpoints from Colab Drive to local for analysis

### For Project
1. Add GPU requirement to README
2. Create separate Colab-specific and local-specific configs
3. Document platform-specific setup (Windows num_workers=0, etc.)
4. Consider creating a tiny subset (1000 images) for quick CPU testing/debugging

---

## Metrics & Statistics

### Dataset (Unchanged)
- Training: 25,572 images (drowsy: 13,359, notdrowsy: 12,213)
- Validation: 19,016 images (drowsy: 9,584, notdrowsy: 9,432)
- Test: 21,933 images (drowsy: 13,087, notdrowsy: 8,846)
- Total: 66,521 frames from 4 subjects (2 train, 1 val, 1 test)

### Training Performance (CPU - Ultrafast Config)
- Image size: 128x128 pixels
- Batch size: 8
- Speed: ~1.4 seconds/batch
- Train batches: 3,196
- Val batches: 2,377
- Estimated epoch time: ~74 minutes training + ~55 minutes validation = **~2.2 hours/epoch**
- **Total for 2 epochs: ~4.4 hours** (impractical)

### Model
- Architecture: ResNet50 (pretrained ImageNet weights)
- Total parameters: 23,512,130
- Trainable parameters: 23,512,130

---

## Successes ✅

1. Successfully created fast training configurations for multiple scenarios
2. Fixed all repository/package issues (requirements.txt, .gitignore, missing modules)
3. Documented comprehensive Colab GPU setup procedure
4. Identified and documented CPU training limitations clearly
5. Maintained clean git history with descriptive commits

---

## Failures ❌

1. Did not complete a full training run (neither Colab nor local)
2. No trained checkpoints or evaluation metrics yet
3. CPU training proved completely impractical for this dataset size
4. User still struggling with Colab GPU setup

---

## Status: In Progress ⚠️

**Blocking Issue:** Need GPU for practical training (Colab or cloud)  
**Ready to Proceed:** All code, configs, and setup instructions complete  
**Waiting On:** User to successfully enable Colab GPU and run training

---

## Repository State

**Branch:** main  
**Latest Commit:** c9b31aa  
**Status:** Clean, all changes pushed  
**Untracked/Ignored:** checkpoints/ (no models trained yet)

---

**Report Generated:** November 18, 2025  
**Next Report:** After successful GPU training completion

---

## End-of-Day Update (Training Stopped Due to Time and Overfitting)

Today’s Colab run showed very slow iteration time when reading images from Google Drive with `num_workers=4` (e.g., ~5.25 s/iteration mid-epoch), and validation metrics continued to degrade after epoch 1. To avoid wasting GPU time, we stopped the training and focused on evaluation and mitigation steps.

Key points:

- Overfitting: validation Macro-F1 decreased after epoch 1 despite improving train metrics.
- Time consumption: epoch duration became long and inconsistent under Drive I/O; validation also slowed.
- Decision: stop current training, evaluate best checkpoint, and resume tomorrow with speed-ups and regularization.

Planned mitigations for next session:

- Copy dataset from Drive to local VM path `datasets/archive` before training.
- Set `data.num_workers: 2` and keep `pin_memory: true` for Colab.
- Use the regularized config (freeze backbone, higher dropout, lower LR, stronger weight decay).
- Optionally switch to EfficientNet-B0 for faster epochs.
