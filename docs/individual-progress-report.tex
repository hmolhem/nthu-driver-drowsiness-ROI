% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\author{}
\date{}

\begin{document}

\hypertarget{ee-6770-final-project-individual-progress-report}{%
\section{EE 6770 -- Final Project: Individual Progress
Report}\label{ee-6770-final-project-individual-progress-report}}

\textbf{Student:} {[}Your Name{]} \textbf{Project:} NTHU Driver
Drowsiness Detection with ROI \textbf{Date:} November 19, 2025

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{part-1-technical-contribution-learning-70}{%
\subsection{Part 1: Technical Contribution \& Learning
(70\%)}\label{part-1-technical-contribution-learning-70}}

\begin{itemize}
\tightlist
\item
  \textbf{Main Roles:}

  \begin{itemize}
  \tightlist
  \item
    Data prep validation (subject-exclusive splits under
    \texttt{data/splits/}).
  \item
    Baseline modeling (ResNet50) and training orchestration in Colab.
  \item
    Evaluation tooling (metrics/plots) and experiment reporting.
  \item
    Runtime analysis and mitigation for time-consuming Colab training.
  \end{itemize}
\item
  \textbf{Implemented \& Tested:}

  \begin{itemize}
  \tightlist
  \item
    \texttt{src/eval/evaluate\_model.py} (new CLI):

    \begin{itemize}
    \tightlist
    \item
      Computes accuracy, macro precision/recall/F1, per-class metrics.
    \item
      Saves confusion matrix CSV and PNGs (raw + normalized), ROC curves
      (per class) with AUC.
    \item
      Exports \texttt{predictions\_test.csv} with probabilities per
      class.
    \end{itemize}
  \item
    Colab workflow (\texttt{notebooks/colab\_gpu\_training.ipynb})
    upgrades:

    \begin{itemize}
    \tightlist
    \item
      Regularized ResNet50 config writer (freeze backbone, dropout 0.7,
      LR 5e-5, WD 5e-4, patience 5, workers 2).
    \item
      Train/eval/export cells for Regularized ResNet50 and
      EfficientNet-B0.
    \item
      Comparison cell to plot Accuracy and Macro-F1 across baselines.
    \item
      Speed-up \& resume cells: copy dataset to VM SSD, patch
      \texttt{num\_workers:\ 2}.
    \end{itemize}
  \item
    Reports:

    \begin{itemize}
    \tightlist
    \item
      \texttt{docs/training-report-nov18-colab.md}: training status,
      overfitting analysis, timings, test results, next steps.
    \item
      \texttt{docs/report-2025-11-18.md}: daily summary and decision to
      stop training (time + generalization).
    \end{itemize}
  \end{itemize}
\item
  \textbf{Evidence (Code, Models, Figures):}

  \begin{itemize}
  \tightlist
  \item
    Checkpoints: \texttt{checkpoints/baseline\_resnet50\_best.pth}
    (epoch 1), \texttt{baseline\_resnet50\_last.pth}.
  \item
    Test (ResNet50 best): Accuracy 0.5818; Macro-F1 0.5806; ROC AUC
    (macro) 0.6415.
  \item
    Generated figures (copied to \texttt{reports/figures/}):

    \begin{itemize}
    \tightlist
    \item
      \texttt{confusion\_matrix\_test.png},
      \texttt{confusion\_matrix\_test\_normalized.png},
      \texttt{roc\_curves\_test.png}.
    \end{itemize}
  \item
    (If run) \texttt{comparison\_baselines.png} (Macro-F1 vs Accuracy
    bar charts).
  \item
    Minimal code snippet (evaluation entry):
  \end{itemize}

\begin{verbatim}
# src/eval/evaluate_model.py (excerpt)
metrics, cls_report, probs, labels = evaluate(model, test_loader, device=device, save_preds_path=preds_csv)
# Save metrics JSON + AUC
metrics_to_save = {k: (v.tolist() if hasattr(v, "tolist") else v) for k, v in metrics.items()}
metrics_to_save["roc_auc"] = roc_auc_scores
\end{verbatim}
\item
  \textbf{Challenge \& Resolution:}

  \begin{itemize}
  \tightlist
  \item
    Challenge: Training on Colab became time-consuming with dataset
    streamed from Google Drive and \texttt{num\_workers=4}
    (\textasciitilde5.25 s/iteration mid-epoch), while validation
    degraded after epoch 1 (classic overfitting).
  \item
    Resolution: Copy dataset to local VM path
    (\texttt{datasets/archive}), reduce \texttt{num\_workers} to 2, keep
    \texttt{pin\_memory:\ true}. Adopt stronger regularization (freeze
    backbone, higher dropout, lower LR, higher WD) and add a lighter
    baseline (EfficientNet-B0) for faster epochs and better
    generalization.
  \end{itemize}
\end{itemize}

\hypertarget{overfitting-analysis}{%
\subsubsection{Overfitting Analysis}\label{overfitting-analysis}}

\begin{longtable}[]{@{}lrrrrl@{}}
\toprule
Epoch & Train Loss & Train Macro-F1 & Val Loss & Val Macro-F1 & Notes \\
\midrule
\endhead
1 & 0.2207 & 0.9071 & 0.8263 & \textbf{0.5772} & Best validation;
checkpoint saved \\
2 & 0.1218 & 0.9524 & 1.2085 & 0.4987 & Validation performance drops
sharply \\
3 & 0.1012 & 0.9602 & 1.4190 & 0.4782 & Further decline; overfitting
intensifies \\
\bottomrule
\end{longtable}

Pattern: Training metrics improve (loss ↓, F1 ↑) while validation loss
increases and Macro-F1 decreases after epoch 1. This divergence
indicates memorization of training samples rather than generalizable
features.

Mitigation steps now in place: backbone freezing, increased dropout,
stronger weight decay, lower learning rate, early stopping patience
reduction, lighter alternative architecture (EfficientNet-B0), and
improved data loading throughput (local copy + fewer workers).

\textbf{Challenge: Training Time (Bold)} -- In addition to overfitting,
the throughput slowdown (≈5.25 s/iteration mid-epoch when reading from
Drive with 4 workers) inflated epoch duration, making rapid
experimentation impractical until mitigations (local copy, fewer
workers) were applied.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{part-2-plan-to-complete-before-final-presentation}{%
\subsection{Part 2: Plan to Complete Before Final
Presentation}\label{part-2-plan-to-complete-before-final-presentation}}

\begin{itemize}
\tightlist
\item
  Near-term experiments (this week):

  \begin{itemize}
  \tightlist
  \item
    Train Regularized ResNet50 (Colab, local dataset copy, 2 workers);
    evaluate and export artifacts.
  \item
    Train EfficientNet-B0; evaluate; run comparison plots
    (\texttt{reports/figures/comparison\_baselines.png}).
  \end{itemize}
\item
  ROI phase: Train ROI-gated approach
  (\texttt{src/models/roi\_gating.py}, \texttt{unet\_segmentation.py})
  focusing on eyes/mouth.
\item
  Reporting: Consolidate metrics/plots, per-class breakdowns; finalize
  slides.
\item
  Practical Colab steps:

  \begin{itemize}
  \tightlist
  \item
    Copy dataset to
    \texttt{/content/nthu-driver-drowsiness-ROI/datasets/archive}, patch
    \texttt{num\_workers:\ 2}, run \texttt{-\/-device\ cuda}.
  \end{itemize}
\item
  Milestones:

  \begin{itemize}
  \tightlist
  \item
    Week 1 (Nov 19--24): Complete regularized + EfficientNet runs and
    comparisons.
  \item
    Week 2: ROI training/evaluation; finalize analysis and slides.
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{project-snapshot}{%
\subsection{Project Snapshot}\label{project-snapshot}}

\begin{itemize}
\tightlist
\item
  Key configs: \texttt{configs/baseline\_resnet50.yaml},
  \texttt{configs/baseline\_resnet50\_regularized.yaml},
  \texttt{configs/baseline\_efficientnet.yaml}.
\item
  Relevant code: \texttt{src/training/train\_baseline.py},
  \texttt{src/training/trainer.py}, \texttt{src/data/dataset.py},
  \texttt{src/data/transforms.py}, \texttt{src/eval/evaluate\_model.py}.
\item
  Notebook: \texttt{notebooks/colab\_gpu\_training.ipynb} (GPU setup →
  train → evaluate → export → compare → speed-up/resume).
\item
  Figures: under \texttt{reports/figures/} (confusion matrices, ROC,
  comparison).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{colab-time-consumption-gpu-findings}{%
\subsection{Colab Time Consumption (GPU) --
Findings}\label{colab-time-consumption-gpu-findings}}

\begin{itemize}
\tightlist
\item
  Baseline reference: \textasciitilde74 minutes for epoch 1 (train
  \textasciitilde42m + val \textasciitilde32m).
\item
  With Drive I/O + 4 workers: \textasciitilde5.25 s/iteration mid-epoch;
  epochs elongated and inconsistent.
\item
  Mitigations: use 2 workers, local dataset copy, regularized setup, or
  EfficientNet-B0.
\end{itemize}

\hypertarget{detailed-training-time-breakdown-resnet50-baseline}{%
\subsubsection{Detailed Training Time Breakdown (ResNet50
Baseline)}\label{detailed-training-time-breakdown-resnet50-baseline}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.29}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.31}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.27}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.13}}@{}}
\toprule
Phase / Epoch & Train Duration & Val Duration & Notes \\
\midrule
\endhead
Epoch 1 & \textasciitilde42 min & \textasciitilde32 min & Includes
initial model + caching overhead \\
Epoch 2 & \textasciitilde5 min & \textasciitilde2.3 min & After caching;
faster I/O \\
Epoch 3 & \textasciitilde5 min (train) & \textasciitilde2.4 min &
Validation degraded; overfitting intensified \\
Drive-I/O worst case (observed mid-epoch) & \textgreater70 min
(projected) & \textgreater30 min (projected) & When streaming directly
from Drive with 4 workers and contention \\
\bottomrule
\end{longtable}

\textbf{Observation:} After the first epoch warms caches, training
becomes much faster if data access is stable. However, reading via
Google Drive with high worker count can revert to slow per-iteration
times (\textasciitilde5.25s/it). Copying the dataset locally plus
reducing workers stabilizes throughput.

\hypertarget{test-set-results-best-checkpoint-epoch-1}{%
\subsubsection{Test Set Results (Best Checkpoint -- Epoch
1)}\label{test-set-results-best-checkpoint-epoch-1}}

\begin{longtable}[]{@{}lr@{}}
\toprule
Metric & Value \\
\midrule
\endhead
Accuracy & 0.5818 \\
Macro Precision & 0.6219 \\
Macro Recall & 0.6152 \\
Macro F1 & 0.5806 \\
ROC AUC (macro) & 0.6415 \\
\bottomrule
\end{longtable}

Per-Class Detail:

\begin{longtable}[]{@{}lrrrr@{}}
\toprule
Class & Precision & Recall & F1 & Support \\
\midrule
\endhead
notdrowsy & 0.4886 & 0.7877 & 0.6031 & 8,846 \\
drowsy & 0.7552 & 0.4427 & 0.5581 & 13,087 \\
\bottomrule
\end{longtable}

\textbf{Interpretation:} Model favors higher recall for notdrowsy and
higher precision for drowsy, indicating a conservative drowsy
classification (missed positives) under current training regime.

\hypertarget{figure-references}{%
\subsubsection{Figure References}\label{figure-references}}

\includegraphics{../reports/figures/confusion_matrix_test.png}
\includegraphics{../reports/figures/confusion_matrix_test_normalized.png}
\includegraphics{../reports/figures/roc_curves_test.png}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{export-to-pdf-options}{%
\subsection{Export to PDF (Options)}\label{export-to-pdf-options}}

\begin{itemize}
\tightlist
\item
  VS Code: Open this file and use ``Markdown: Print to PDF'' (or the
  Markdown PDF extension).
\item
  Pandoc (if installed):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pandoc docs}\OperatorTok{/}\NormalTok{individual}\OperatorTok{{-}}\NormalTok{progress}\OperatorTok{{-}}\NormalTok{report}\OperatorTok{.}\FunctionTok{md} \OperatorTok{{-}}\NormalTok{o docs}\OperatorTok{/}\NormalTok{individual}\OperatorTok{{-}}\NormalTok{progress}\OperatorTok{{-}}\NormalTok{report}\OperatorTok{.}\FunctionTok{pdf}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{repository-links}{%
\subsection{Repository Links}\label{repository-links}}

\begin{itemize}
\tightlist
\item
  \textbf{GitHub Repository:}
  \href{https://github.com/hmolhem/nthu-driver-drowsiness-ROI}{hmolhem/nthu-driver-drowsiness-ROI}
\item
  \textbf{Documentation Folder:}
  \href{https://github.com/hmolhem/nthu-driver-drowsiness-ROI/tree/main/docs}{docs/}
\item
  \textbf{Evaluation Figures:}
  \href{https://github.com/hmolhem/nthu-driver-drowsiness-ROI/tree/main/reports/figures}{reports/figures/}
\item
  \textbf{Training Notebooks:}
  \href{https://github.com/hmolhem/nthu-driver-drowsiness-ROI/blob/main/notebooks/colab_gpu_training.ipynb}{notebooks/colab\_gpu\_training.ipynb}
\item
  \textbf{Latest Release:}
  \href{https://github.com/hmolhem/nthu-driver-drowsiness-ROI/releases/tag/v0.1-eval-baseline}{v0.1-eval-baseline}
\end{itemize}

\end{document}
