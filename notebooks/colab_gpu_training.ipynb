{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c00289f",
   "metadata": {},
   "source": [
    "## Step 1: Verify GPU is Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ee3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b34b0",
   "metadata": {},
   "source": [
    "**Expected output:** Should show GPU info (Tesla T4, L4, or similar)\n",
    "\n",
    "**If you see an error:** Go back and enable GPU runtime!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8ce32",
   "metadata": {},
   "source": [
    "## Step 2: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279e767",
   "metadata": {},
   "source": [
    "**Action required:** Click the link and authorize access to your Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece1852",
   "metadata": {},
   "source": [
    "## Step 3: Clone Project from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone https://github.com/hmolhem/nthu-driver-drowsiness-ROI.git\n",
    "%cd nthu-driver-drowsiness-ROI\n",
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbfb69",
   "metadata": {},
   "source": [
    "**Expected:** Shows \"On branch main\" and clean working tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f0e57",
   "metadata": {},
   "source": [
    "## Step 4: Set Up Dataset Symlink\n",
    "\n",
    "This links your Drive dataset to the project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a34dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets directory\n",
    "!mkdir -p datasets\n",
    "\n",
    "# Create symlink to your Drive dataset\n",
    "# Adjust the path if your dataset is in a different location\n",
    "!ln -s /content/drive/MyDrive/datasets/archive datasets/archive\n",
    "\n",
    "# Verify the symlink works\n",
    "!ls -lh datasets/\n",
    "!ls datasets/archive/drowsy | head -3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3c962",
   "metadata": {},
   "source": [
    "**Expected:** Should list 3 image files from drowsy folder\n",
    "\n",
    "**If error:** Adjust the path in the `ln -s` command to match your Drive structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9de33",
   "metadata": {},
   "source": [
    "## Step 5: Verify Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c05fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check splits exist\n",
    "!ls -lh data/splits/\n",
    "!head -3 data/splits/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0897bbc",
   "metadata": {},
   "source": [
    "**Expected:** Shows train.csv, val.csv, test.csv with sizes and first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47eb684",
   "metadata": {},
   "source": [
    "## Step 6: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbe80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA support\n",
    "!pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision -U\n",
    "\n",
    "# Install other requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56687c49",
   "metadata": {},
   "source": [
    "**Note:** May see some warnings about version conflicts — these are usually harmless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1967ab",
   "metadata": {},
   "source": [
    "## Step 7: Verify CUDA PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU device:', torch.cuda.get_device_name(0))\n",
    "    print('GPU memory:', torch.cuda.get_device_properties(0).total_memory / 1e9, 'GB')\n",
    "else:\n",
    "    print('WARNING: CUDA not available! Go enable GPU runtime.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4948a9f",
   "metadata": {},
   "source": [
    "**Expected:** \n",
    "- `CUDA available: True`\n",
    "- GPU device: Tesla T4, L4, or similar\n",
    "\n",
    "**If False:** Stop here and enable GPU runtime!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77edb4e",
   "metadata": {},
   "source": [
    "## Step 8: Start Training (ResNet50 Baseline)\n",
    "\n",
    "This will take ~30-60 minutes depending on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with full baseline config (224px, 50 epochs with early stopping)\n",
    "!python src/training/train_baseline.py --config configs/baseline_resnet50.yaml --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c092f",
   "metadata": {},
   "source": [
    "**What to expect:**\n",
    "- Progress bars for each epoch\n",
    "- Training loss should decrease over time\n",
    "- Validation metrics printed after each epoch\n",
    "- Early stopping may trigger before 50 epochs if val metric plateaus\n",
    "- Checkpoints saved to `checkpoints/baseline_resnet50_best.pth` and `_last.pth`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8254606",
   "metadata": {},
   "source": [
    "## Step 9: Verify Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc454f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df025340",
   "metadata": {},
   "source": [
    "**Expected:** Should see `baseline_resnet50_best.pth` and `baseline_resnet50_last.pth` (~90 MB each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3fd7c3",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.classifier import create_model\n",
    "from src.data.transforms import get_val_transforms\n",
    "from src.data.dataset import create_dataloaders\n",
    "from src.utils.config import get_config\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load config\n",
    "cfg = get_config(\"configs/baseline_resnet50.yaml\")\n",
    "cfg.data.num_workers = 2  # Colab-friendly\n",
    "\n",
    "# Create test dataloader\n",
    "val_tf = get_val_transforms(cfg.data.image_size)\n",
    "loaders = create_dataloaders(\n",
    "    cfg.data.train_csv, cfg.data.val_csv, cfg.data.test_csv,\n",
    "    data_root=cfg.data.data_root,\n",
    "    train_transform=val_tf,\n",
    "    val_transform=val_tf,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    num_workers=cfg.data.num_workers\n",
    ")\n",
    "\n",
    "# Load model with best checkpoint\n",
    "model = create_model(cfg)\n",
    "ckpt = torch.load(\"checkpoints/baseline_resnet50_best.pth\", map_location=\"cuda\")\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "model.cuda().eval()\n",
    "\n",
    "print(\"Best checkpoint from epoch:\", ckpt.get('epoch', 'unknown'))\n",
    "print(\"Best val macro-F1:\", ckpt.get('val_macro_f1', 'unknown'))\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "# Run inference on test set\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in loaders['test']:\n",
    "        images = images.cuda()\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(1).cpu()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(all_labels, all_preds, target_names=['notdrowsy', 'drowsy']))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "print(\"\\n[Row: True label | Column: Predicted label]\")\n",
    "print(\"[0=notdrowsy, 1=drowsy]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898ca99",
   "metadata": {},
   "source": [
    "## Step 11: Copy Checkpoints to Drive (for backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create backup directory on Drive\n",
    "!mkdir -p /content/drive/MyDrive/drowsiness-results/checkpoints\n",
    "\n",
    "# Copy checkpoints\n",
    "!cp checkpoints/baseline_resnet50_best.pth /content/drive/MyDrive/drowsiness-results/checkpoints/\n",
    "!cp checkpoints/baseline_resnet50_last.pth /content/drive/MyDrive/drowsiness-results/checkpoints/\n",
    "\n",
    "print(\"✅ Checkpoints backed up to Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5f06a",
   "metadata": {},
   "source": [
    "## Step 12: Download Checkpoints (Optional)\n",
    "\n",
    "If you want to download directly to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Create a zip of checkpoints\n",
    "!zip -r baseline_resnet50_checkpoints.zip checkpoints/baseline_resnet50_*.pth\n",
    "\n",
    "# Download the zip\n",
    "files.download('baseline_resnet50_checkpoints.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11f1bd",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After successful training:\n",
    "\n",
    "1. **Download checkpoints** to your local machine\n",
    "2. **Train EfficientNet-B0 baseline** for comparison:\n",
    "   ```python\n",
    "   !python src/training/train_baseline.py --config configs/baseline_efficientnet.yaml --device cuda\n",
    "   ```\n",
    "3. **Compare results** and create performance tables\n",
    "4. **Begin ROI implementation** (next phase)\n",
    "\n",
    "---\n",
    "\n",
    "**Troubleshooting:**\n",
    "- **CUDA not available:** Enable GPU runtime\n",
    "- **Dataset not found:** Check Drive path in symlink command\n",
    "- **Out of memory:** Reduce batch_size in config\n",
    "- **Import errors:** Re-run pip install cell"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
