# EfficientNet-B0 Baseline Configuration (Regularized)
# Lighter architecture to reduce overfitting and training time

model:
  name: "efficientnet_b0_baseline"
  architecture: "efficientnet_b0"
  pretrained: true
  num_classes: 2
  freeze_backbone: false        # Start unfrozen; consider freezing if overfitting persists
  dropout: 0.5                  # Built-in classifier dropout layer

data:
  data_root: "datasets"         # Use symlink/copy path without archive
  train_csv: "data/splits/train.csv"
  val_csv: "data/splits/val.csv"
  test_csv: "data/splits/test.csv"
  image_size: 224
  batch_size: 32
  num_workers: 2
  pin_memory: true

augmentation:
  enabled: true
  horizontal_flip: 0.5
  color_jitter:
    brightness: 0.25
    contrast: 0.25
    saturation: 0.25
    hue: 0.08
  rotation_degrees: 10
  random_affine:
    translate: [0.08, 0.08]
    scale: [0.95, 1.05]

training:
  epochs: 40                    # Slightly more epochs; smaller model
  optimizer: "adam"
  learning_rate: 0.0001         # Standard starting point; lower if unstable
  weight_decay: 0.0005          # Stronger than classic 1e-4
  lr_scheduler:
    type: "reduce_on_plateau"
    mode: "max"
    factor: 0.5
    patience: 4
    min_lr: 0.000001
  loss:
    type: "weighted_cross_entropy"
    use_class_weights: true
  early_stopping:
    enabled: true
    patience: 4
    monitor: "val_macro_f1"
    mode: "max"
    min_delta: 0.0001
  gradient_clipping:
    enabled: true
    max_norm: 1.0

logging:
  experiment_name: "efficientnet_b0_baseline"
  log_dir: "runs"
  save_dir: "checkpoints"
  log_interval: 0
  save_best_only: true
  save_last: true

seed: 42
device: "cuda"